# üåü Awesome LLM Reasoning

<p align="center">
  <img src="assets/banner.png" alt="LLM Reasoning Meme Banner" width="800"/>
</p>

> A curated list of resources on reasoning in Large Language Models (LLMs), including papers, methods, benchmarks, datasets, and tools.

LLMs are advancing from text generation to intelligent reasoning. This list aims to collect key building blocks for understanding and improving reasoning in LLMs.

---
üìÑ Read this in:
[English](README.md) | [‰∏≠Êñá](README.zh.md)

## üìö Table of Contents

- [Foundational Papers](#foundational-papers)
- [Evaluation Benchmarks](#evaluation-benchmarks)
- [Reasoning Techniques](#reasoning-techniques)
- [Datasets](#datasets)
- [Reasoning Types](#reasoning-types)
- [Surveys & Reviews](#surveys--reviews)
- [Real-World Applications](#real-world-applications)
- [Open-Source Tools](#open-source-tools)
- [Contribute](#contribute)

---

## üß† Foundational Papers

- [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)
- [Self-Consistency Improves Chain of Thought Reasoning](https://arxiv.org/abs/2203.11171)
- [Program Induction by Rationale Generation](https://arxiv.org/abs/1705.04146)
- [Neural-Symbolic Solver for Math Word Problems](https://arxiv.org/abs/2107.01431)
- [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)
- [Tree of Thoughts: Deliberate Problem Solving with LLMs](https://arxiv.org/abs/2305.10601)

---

## üìè Evaluation Benchmarks

- [GSM8K](https://github.com/openai/grade-school-math)
- [MATH](https://github.com/hendrycks/math)
- [BIG-Bench](https://github.com/google/BIG-bench)
- [MATH500](https://huggingface.co/datasets/ndavidson/sat-math-chain-of-thought)
- [AGIEval](https://huggingface.co/datasets/AGIEval)
- [BBH](https://github.com/suzgunmirac/Beyond-the-Imitation-Game-Benchmark)

---

## ‚öôÔ∏è Reasoning Techniques

- **Prompting**: Zero-shot, few-shot, CoT, Least-to-Most
- **Planning**: ReAct, Tree-of-Thoughts, Self-Ask
- **Search**: MCTS, ReST-MCTS*
- **External Tools**: Calculator, Python interpreter
- **RL Fine-Tuning**: RLHF, DPO

---

## üß™ Datasets

- [GSM8K](https://huggingface.co/datasets/gsm8k)
- [MATH](https://huggingface.co/datasets/hendrycks/math)
- [SVAMP](https://huggingface.co/datasets/ChilleD/SVAMP)
- [AQUA-RAT](https://huggingface.co/datasets/aqua_rat)
- [ProofWriter](https://allenai.org/data/proofwriter)
- [ParaMAWPS](https://github.com/SR-Rifat/ParaMAWPS)

---

## üß© Reasoning Types

- Deductive
- Inductive
- Commonsense
- Multi-hop
- Mathematical
- Causal

---

## üßæ Surveys & Reviews

- [Large Language Models for Mathematical Reasoning](https://arxiv.org/abs/2402.00157)
- [Are NLP Models Really Able to Solve Simple Math Word Problems?](https://arxiv.org/abs/2103.07191)
- [Learning by Analogy: Diverse Math Word Problem Generation](https://arxiv.org/abs/2306.09064)
- [Systematic Evaluation of Chain-of-Thought Prompting](https://arxiv.org/abs/2309.00843)

---

## üåç Real-World Applications

- **Education**: AI tutors, math assistants
- **Search Engines**: Multi-hop question answering
- **Science**: Symbolic tools + models
- **Legal/Finance**: Structured reasoning and auditability
- **Medical**: Clinical diagnostic reasoning

---

## üõ† Open-Source Tools

- [LangChain](https://github.com/langchain-ai/langchain)
- [Open-Interpreter](https://github.com/KillianLucas/open-interpreter)
- [ReAct Agents](https://github.com/ysymyth/ReAct)
- [AutoGPT](https://github.com/Torantulino/Auto-GPT)
- [HuggingFace Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open-llm-leaderboard)

---


### Contributors

<a href="https://github.com/IngredientPreppers/Awesome-LLM-Reasoning/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=IngredientPreppers/Awesome-LLM-Reasoning" />
</a>